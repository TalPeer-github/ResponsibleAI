![header](https://capsule-render.vercel.app/api?type=waving&color=5B0888&height=300&section=header&text=Responsible%20AI-nl-&fontSize=65&animation=fadeIn&fontColor=F1EAFF&desc=Final%20Project&descSize=46&stroke=243A73&strokeWidth=0)
![header](https://capsule-render.vercel.app/api?type=transparent&color=5B0888&height=65&reversal=true&textBg=True&fontSize=24&fontColor=E5CFF7&text=%20Faculty%20of%20Data%20and%20Decisions%20Science%20-nl-%20&desc=%20Technion%20-%20Israel%20Institute%20of%20Technology&descSize=18&descAlignY=70&fontAlign=50&animation=fadeIn&textBg=True&section=header&stroke=243A73&strokeWidth=0&theme=holi)
![header](https://capsule-render.vercel.app/api?type=transparent&color=5B0888&height=65&reversal=true&textBg=True&fontSize=24&fontColor=E5CFF7&text=Faculty%20of%20Law%20-nl-%20&desc=%20Tel-Aviv%20University&descSize=18&descAlignY=70&descAlignX=50&fontAlign=50&animation=fadeIn&textBg=True&section=header&stroke=243A73&strokeWidth=0&theme=holi)


![footer](https://capsule-render.vercel.app/api?type=waving&color=5B0888&height=100&section=footer&text=%20-nl-%20Spring%202024%20%20&fontSize=28&fontAlign=50&fontColor=F1EAFF&theme=holi)


![header](https://capsule-render.vercel.app/api?type=soft&color=5B0888&height=45&section=header2&text=Authors&fontSize=28&fontAlign=7&fontColor=E5CFF7&reversal=false&theme=holi)
> Tal Peer tal.peer@campus.technion.ac.il
> 
> Carmel Soceanu
> 
> John Farran 
>
> Shahaf Karp
>
> Noam Ronen
>
> Chaim Danino

![header](https://capsule-render.vercel.app/api?type=soft&color=5B0888&height=45&section=header&text=Background&fontSize=28&fontAlign=10&fontColor=E5CFF7&reversal=true&theme=holi)

In this project, we conduct an algorithmic audit of an AI system within a concrete context.<br>
The audit requires the integration of technological, legal, and ethical perspectives on novel case studies, values, and sectors.<br>

![header](https://capsule-render.vercel.app/api?type=transparent&color=5B0888&height=30&section=header&text=Algorithmic%20Audits&fontSize=20&fontAlign=11.5&fontColor=E5CFF7&reversal=false&textBg=true&theme=holi)

Audits of automated decision systems are proposed as a way to curb discrimination and disinformation, and to hold those who deploy algorithmic decision-making accountable for their harms.<br>
Many other uses of related terms, such as impact assessment, also impose obligations on covered entities to benchmark the development and implementation of algorithmic systems against some acceptable standard.

![header](https://capsule-render.vercel.app/api?type=transparent&color=5B0888&height=30&section=header&text=Human%20In%20%The%20Loop&fontSize=20&fontAlign=11.5&fontColor=E5CFF7&reversal=false&textBg=true&theme=holi)

Our project aims to audit an AI system within the context of **Human In The Loop** - <br>
Decisions performed by AI have prompted regulators to require some level of human involvement in autonomous systems.<br><br>
At the same time, studies show that humans tend to defer to AI systems, which raise some important questions. Some examples:<br> 
- When and how can humans refine outcomes of AI systems?<br>
- How to design such hybrid decision-making processes?<br>
- What are the legal and ethical implications of introducing humans in the loop? 

![header](https://capsule-render.vercel.app/api?type=soft&color=5B0888&height=45&section=header&text=Dependencies&fontSize=28&fontAlign=11.5&fontColor=E5CFF7&reversal=true&theme=holi)

Project environment dependencies are listed in `requirements.txt`.
From the project root folder, run:

```bash
pip install -r requirements.txt
```


![header](https://capsule-render.vercel.app/api?type=soft&color=5B0888&height=45&section=header&text=Acknowledgment&fontSize=28&fontAlign=14&fontColor=E5CFF7&reversal=true&theme=holi)

Course information can be found on https://learn.responsibly.ai/2024-spring-tau-technion/ <br>
All Rights Reserved.
